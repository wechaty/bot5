# 浅谈人机对话

> **写在前面**
> 写这篇blog，目的是希望帮助初步接触人机对话的同学可以对这一块的工作有个相对完整的了解
> 并针对人机对话可以做和比较难做的地方做了一些讨论，以便大家可以在做这方面产品的时候知道如何划分人机对话的能力边界

## 引子

在开始之前，想请大家先思考个问题：

```bash
在和人沟通的时候，大家经常会担心并会说的一句话是什么？

嗯，不要想太复杂，其实是这两句：

说话的人：听明白我的意思了么？
听的人：你说的是什么意思？
```

这也很好理解，沟通的目的就是为了传递思想，如果哇啦哇啦说半天，对方还没有明白，那是多沮丧的一件事情。

现在我们来换个角度看这个事情，如果把人看成一台机器，那么机器和机器之间用什么东西来沟通呢？
技术男们马上会说，肯定是走协议啊，就好像tcpip那样，要传递什么数据，都基于协议来就好啦。
嗯，很有道理的样子，那么，是不是可以这么认为，语言其实也是一种协议，是人们为了可以帮助传递自己内心的想法而定义的一些规则，
大家都按照这个规则来做，那么互相之间表达一些思想就没问题啦。

嗯嗯，中文是一种协议，英文是另外一种协议，想想世界上这么多国家，好像人类之间用的协议也蛮多的哦。
站在这个角度，人机对话的核心就应该是让机器理解这些协议啦。

## 实现对话的基本方法

继续往下之前，我们先来看看两个例子：

- 我要去公园
- 今天北京的天气怎么样

当我们听到这两句话的时候，脑袋里就会浮现出这些信息：
我要去公园，嗯嗯，应该是想出去玩了，而且是室外，有花有草的地方。
今天北京的天气怎么样，想知道今天北京的天气，冷还是热，晴天还是下雨。

其实这个过程，就是大脑在下意识处理话语的意图的过程，每当一个人说一句话出来，我们听到了以后第一反应就是，他想表达什么。
然后在表达的这些信息中，最关键的信息是什么。

如果要特别标明出来，大概是这样的：

- 我要**去公园**
- **今天北京**的**天气**怎么样

加粗的字体部分就是关键信息，可以帮助我们更准确理解说话的人想表达的意思。

其实，机器实现对话的过程也是基本类似这样的：

```bash
首先，判断你想表达的意图是什么
其次，找到其中的关键信息
根据意图和关键信息，生成带条件的命令去执行
```

我们用个完整的具体再分析一下看看：
**请提醒我明天上午10点去开会**
这句话的分析结果如下：

- 核心目的：帮我设置一个提醒
- 关键信息：明天上午10点     去开会
- 翻译成代码逻辑：
创建一条去开会的任务，任务的截止时间明天上午10点，并且会在那个时候提醒我

是不是很简答，：）

那么，怎么能够让机器理解一个人说话的意图，并且把关键的信息识别出来呢？
听起来好想好难的样子，完全无从下手啊，用神经网络去训练么？对于我这样的算法渣，这完全是Mission Impossible。。。

很happy的是，今时已不同于往日，大厂们都在争先恐后地“做慈善”（“圈地”），这些都不要我们自己来做啦，现成的平台，免费的接口，让人睡觉都能笑醒啊。
好吧，我知道你们也很着急，那就赶紧来看看这些大厂的平台到底做的怎么样吧。
电影「Her」中的场景再现，是不是不远了，嘿嘿。。。

## 常见平台的实现方法

由于篇幅的原因，咱们主要对比百度的Unit和微软的Luis两个平台，
例句同样是这个：请提醒我明天上午10点去开会

先来看看百度的：

**百度Unit**
按照百度官方的推荐方法，要识别这句话的意图，并且挑出关键信息，
最基本的，需要做这几点事情：

1. 先定义意图
2. 定义一系列的词槽
3. 将词槽和意图进行关联
4. 在意图下面，定义一套或者多套模版，模版由前面关联好的词槽组成
5. 训练
6. 测试结果

嗯嗯，好专业的样子，那我们就开始把！

首先，创建一个意图

```bash
CREATE_TASK
```

接下来，定义几个词槽，后面关键信息的挑取，就靠这些词槽了，所以要好好思考一下怎么定义

```bash
[Op.Remind] ：提醒、通知
[UserName] ：通用人名、代词的词槽
[DateTime] ：通用时间词槽
```

然后，为意图添加一个模版
|意图|模版内容|模版片段顺序|必须匹配|
|:-:|:-:|:-:|:-:|
|CREATE_TASK|[Op.Remind]|1|是|
||[UserName]|2|否|
||[DateTime]|2|是|

在这套模版里面，`[Op.Remind]`和`[DateTime]`是必须要有的，
也就是说当一句话中这两个词槽都能匹配到的时候，就会认为这句话想表达一个`CREATE_TASK`的意图了，是不是挺简单？

使用Unit的这套方法，优点明显，缺点同样不少：

- 优点
  - 在对话样本数极少的时候，规则可以快速达到还不错的效果
  - 基于规则，可以比较明确知道匹配的边界
  - 词槽的不同值加上模版，有一定的灵活度，较好理解

- 缺点
  - 模版没有覆盖到的，基本就不行
  - 对模版、词槽的配置能力有一定的要求
  - 话术的学习泛化能力有点惨

接下来看看微软的，这个昔日的王者，在语义理解上能做到一个什么样的高度：

**微软Luis**
微软的做法相对比较简单，他不推荐使用模版来做，而是直接将对话的话术给他，他自己训练，就可以了。
基本的步骤是这样的：

1. 定义意图（intent）
2. 定义实体（entities）
3. 准备一些针对意图的话术
4. 训练
5. 测试结果

嗯，马上开始：
第一步，话术的收集整理（可以认为是机器学习的**训练集**数据）

```bash
1、5分钟以后提醒我去3楼开会
2、添加一条下午3点的任务，预定会议室，并准备好纸笔
3、和小明说一下下周三下午开全体大会
……
```

接下来，定义实体 - 用来提取关键信息

```bash
[DateTime] ：系统默认实体
[UserName] ：系统默认实体
[Op.Remind] ：提醒、通知
[Op.Add] ：添加、增加、创建、……
[Name.Task] ：任务、提醒、事项、安排、……
```

然后训练，测试，结果应该类似下面这样：

请提醒我明天上午10点去开会

```bash
intent：CREATE_TASK
entites：
   [Op.Remind] ：提醒
   [Datetime] ：明天上午10点
   [UserName] ：我
```

是不是感觉luis简单了很多？反正我在用的过程中感觉轻松惬意，：）
当然，优点很多，也有一些需要注意的问题点：

- 优点
  - 几句简单典型的话术，即可实现一定程度的泛化能力
  - 对配置的要求低
  - 训练是一个愉悦的过程

- 缺点
  - 训练集的数据质量很重要，训练结果会有一定的不确定性
  - 为了保证每次调整后的效果，测试集的整体测试很重要
  - 实体基于正则的方式匹配出来，误差略大

使用这些平台，是可以解决所有的对话问题么？
理想是丰满的，现实是骨感的，遗憾的是，现在所有的对话平台，都还不算处理的太好。

我找几个典型的句式给大家看看：

## 几个典型问题

- 模版式匹配的局限
查询小明创建的任务
如果用模版式匹配，就会发现：查询任务、创建任务，都可以被匹配到，那么这句话到底是想查询任务还是创建任务呢？
当然，我们人一眼就能看出来，机器嘛，咳咳。。。

- 分词的错误
上**周小明**的文档在哪里
嗯，很无语是不是，他会认为周小明是个人名，但其实我想表达的是，**上周** **小明** 的文档在哪里？。。。

- 正则方式拿到实体的误差
有没**有关**键时刻这个文档
好吧，偷偷滴告诉你，不管是词槽，还是实体，挑关进信息的方式都是正则，是不是让你很沮丧
所以他告诉我，这里面有个词叫有关，会不会有点崩溃
我在这里定义**有关**这个词槽的目的是为了能够提取前面的关键词的，比如：
**会员**有关的文档，**会员**两个字就是我想要找的关键词，如果**有关**这个词槽匹配错了，我的结果自然也就错了

- 关键信息多且说法多样
找下小明执行小张关注的任务
找下小明执行关注人是小张的任务
这两句话，都是为了得到关键信息：小明-执行者，小张-关注者
但怎么拿到呢？词槽或者实体只能单纯把这些信息挑出来，但小明还是小张是执行者，怎么判断？根据文字的位置远近？显然不行对吧

来，给大家个题目，思考一下，这两句话如何处理：

```bash
1、产品运营项目下小明执行的会员系统相关的任务，帮我找下
2、和小张说一下，明天下午3点提醒大家去3层会议室开会，提前5分钟提醒他
```

嗯，这里说到的还是一些简单的，做不太好的问题，其实，人机对话现在能做到的，还真的很少。
要真正做到像电影「Her」那样的流畅对话，路漫漫其修远兮。。。

## 人机对话的空间和局限

**咱们看看这个问话**
如果有人这么说

```bash
今天天气冷吗？
```

如果是人的话，从里面可以看出好多的意图来

```bash
是否可以出门？
需要多穿衣服吗？
是不是不能爬山？
```

这些意图可能是并行存在的，对于机器，怎么做呢？

**再来看看这句**
如果听到一句这样的话：

```bash
这个网站很重要，记得保存一下啊
```

可能直男会这么做

```bash
把这个网站赶紧放入收藏夹
```

然后？就木有然后了。。。
但其实，稍微有点情商的人，一定会仔细分析里面的含义

```bash
这是一个卖花的网站
最近是不是她生日了
她心情不好，求安慰？
```

表面上是让你去收藏一个网站，但其实可能会有另外的意图，
这个，机器又该怎么处理呢？

随便列举一些人之间的对话特点：

- 用户话术充满多样性和随意性
- 正常交流中有大量多意图对话
- 隐性对话信息机器无法获得
- 机器的自主个性化回复还不太好

你会发现，要处理好太复杂了，因为人有思想，会联想，会推理
intent + entity，还不能很好解决这些问题

## 写在最后

**人机对话注定是个细活儿**
好吧，其实也没有那么悲观，我们把人机对话要解决的领域收窄一点，
比如只解决开关灯的问题，只回复天气，这样看起来是不是简单很多？而且会发现很容易实现。
但由于用户的多样性对话话术，不同的语言习惯的表达，即使是这么窄的领域，要真正做的很好，也需要做大量的对话细节处理工作。
只有这样才可能让机器看起来更像人。

现在机器学习的技术发展也的确是突飞猛进，可能不久的将来，「Her」的场景就能真实再现了吧，：）
